{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris Flower Classification using SLP with Python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMosPJwKYwavcjWtbP2WFyS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfianhid/Iris-Flower-Classification-using-SLP-with-Python/blob/main/Iris_Flower_Classification_using_SLP_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWDNngEN1ZSv"
      },
      "source": [
        "**Pertama, kita impor library yang dibutuhkan untuk proses training dan plotting data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz9apGDiCdfq"
      },
      "source": [
        "from __future__ import print_function\n",
        "import matplotlib\n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE9FuWEf1q0b"
      },
      "source": [
        "**Kedua, kita definisikan function 'predict' untuk memprediksi data berdasarkan hasil training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKx3zp_cyAwG"
      },
      "source": [
        "def predict(inputs, weights):\n",
        "    activation = 0.0\n",
        "    for i, w in zip(inputs, weights):\n",
        "        activation += i*w\n",
        "    return 1.0 if activation >= 0.0 else 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsZHaSssLy4b"
      },
      "source": [
        "**Ketiga, kita definisikan function 'plot' untuk memplotting data berdasarkan hasil training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcxfUPdiyDFg"
      },
      "source": [
        "def plot(matrix, weights=None, title=\"Prediction Matrix\"):\n",
        "\n",
        "    if len(matrix[0]) == 3:  # if 1D inputs, excluding bias and ys\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.set_title(title)\n",
        "        ax.set_xlabel(\"i1\")\n",
        "        ax.set_ylabel(\"Classifications\")\n",
        "\n",
        "        if weights != None:\n",
        "            y_min = -0.1\n",
        "            y_max = 1.1\n",
        "            x_min = 0.0\n",
        "            x_max = 1.1\n",
        "            y_res = 0.001\n",
        "            x_res = 0.001\n",
        "            ys = np.arange(y_min, y_max, y_res)\n",
        "            xs = np.arange(x_min, x_max, x_res)\n",
        "            zs = []\n",
        "            for cur_y in np.arange(y_min, y_max, y_res):\n",
        "                for cur_x in np.arange(x_min, x_max, x_res):\n",
        "                    zs.append(predict([1.0, cur_x], weights))\n",
        "            xs, ys = np.meshgrid(xs, ys)\n",
        "            zs = np.array(zs)\n",
        "            zs = zs.reshape(xs.shape)\n",
        "            cp = plt.contourf(xs, ys, zs, levels=[-1, -0.0001, 0, 1], colors=('b', 'r'), alpha=0.1)\n",
        "\n",
        "        c1_data = [[], []]\n",
        "        c0_data = [[], []]\n",
        "\n",
        "        for i in range(len(matrix)):\n",
        "            cur_i1 = matrix[i][1]\n",
        "            cur_y = matrix[i][-1]\n",
        "\n",
        "            if cur_y == 1:\n",
        "                c1_data[0].append(cur_i1)\n",
        "                c1_data[1].append(1.0)\n",
        "            else:\n",
        "                c0_data[0].append(cur_i1)\n",
        "                c0_data[1].append(0.0)\n",
        "\n",
        "        plt.xticks(np.arange(x_min, x_max, 0.1))\n",
        "        plt.yticks(np.arange(y_min, y_max, 0.1))\n",
        "        plt.xlim(0, 1.05)\n",
        "        plt.ylim(-0.05, 1.05)\n",
        "\n",
        "        c0s = plt.scatter(c0_data[0], c0_data[1], s=50.0, c='r', label='Setosa')\n",
        "        c1s = plt.scatter(c1_data[0], c1_data[1], s=50.0, c='b', label='Virginica')\n",
        "\n",
        "        plt.legend(fontsize=10, loc='best')\n",
        "        plt.show()\n",
        "        return\n",
        "\n",
        "    if len(matrix[0]) == 4:  # if 2D inputs, excluding bias and ys\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.set_title(title)\n",
        "        ax.set_xlabel(\"i1\")\n",
        "        ax.set_ylabel(\"i2\")\n",
        "\n",
        "        if weights != None:\n",
        "            map_min = 0.0\n",
        "            map_max = 1.1\n",
        "            y_res = 0.001\n",
        "            x_res = 0.001\n",
        "            ys = np.arange(map_min, map_max, y_res)\n",
        "            xs = np.arange(map_min, map_max, x_res)\n",
        "            zs = []\n",
        "            for cur_y in np.arange(map_min, map_max, y_res):\n",
        "                for cur_x in np.arange(map_min, map_max, x_res):\n",
        "                    zs.append(predict([1.0, cur_x, cur_y], weights))\n",
        "            xs, ys = np.meshgrid(xs, ys)\n",
        "            zs = np.array(zs)\n",
        "            zs = zs.reshape(xs.shape)\n",
        "            cp = plt.contourf(xs, ys, zs, levels=[-1, -0.0001, 0, 1], colors=('b', 'r'), alpha=0.1)\n",
        "\n",
        "        c1_data = [[], []]\n",
        "        c0_data = [[], []]\n",
        "        for i in range(len(matrix)):\n",
        "            cur_i1 = matrix[i][1]\n",
        "            cur_i2 = matrix[i][2]\n",
        "            cur_y = matrix[i][-1]\n",
        "            if cur_y == 1:\n",
        "                c1_data[0].append(cur_i1)\n",
        "                c1_data[1].append(cur_i2)\n",
        "            else:\n",
        "                c0_data[0].append(cur_i1)\n",
        "                c0_data[1].append(cur_i2)\n",
        "\n",
        "        plt.xticks(np.arange(0.0, 1.1, 0.1))\n",
        "        plt.yticks(np.arange(0.0, 1.1, 0.1))\n",
        "        plt.xlim(0, 1.05)\n",
        "        plt.ylim(0, 1.05)\n",
        "\n",
        "        c0s = plt.scatter(c0_data[0], c0_data[1], s=50.0, c='r', label='Setosa')\n",
        "        c1s = plt.scatter(c1_data[0], c1_data[1], s=50.0, c='b', label='Virginica')\n",
        "\n",
        "        plt.legend(fontsize=10, loc='best')\n",
        "        plt.show()\n",
        "        return\n",
        "\n",
        "    print(\"Matrix dimensions not covered.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6-BzwPyMAYF"
      },
      "source": [
        "**Keempat, kita definisikan function 'accuracy' untuk menghasilkan tingkat akurasi prediksi data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3wCTBx4yMwU"
      },
      "source": [
        "# each matrix row: up to last row = inputs, last row = y (classification)\n",
        "\n",
        "def accuracy(matrix, weights):\n",
        "    num_correct = 0.0\n",
        "    preds = []\n",
        "    for i in range(len(matrix)):\n",
        "        pred = predict(matrix[i][:-1], weights)  # get predicted classification\n",
        "        preds.append(pred)\n",
        "        if pred == matrix[i][-1]:\n",
        "            num_correct += 1.0\n",
        "    print(\"Predictions:\", preds)\n",
        "    return num_correct/float(len(matrix))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDVS4s1NMeOv"
      },
      "source": [
        "**Kelima, kita definisikan function 'training_weights' untuk menghasilkan tingkat akurasi training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "576HZst-yS19"
      },
      "source": [
        "# each matrix row: up to last row = inputs, last row = y (classification)\n",
        "\n",
        "def train_weights(matrix, weights, nb_epoch=10, l_rate=1.00, do_plot=False, stop_early=True, verbose=True):\n",
        "    for epoch in range(nb_epoch):\n",
        "        cur_acc = accuracy(matrix, weights)\n",
        "        print(\"\\nEpoch %d \\nWeights: \" % epoch, weights)\n",
        "        print(\"Accuracy: \", cur_acc)\n",
        "\n",
        "        if cur_acc == 1.0 and stop_early:\n",
        "            break\n",
        "        # if do_plot and len(matrix[0])==4: plot(matrix,weights) # if 2D inputs, excluding bias\n",
        "        if do_plot:\n",
        "            plot(matrix, weights, title=\"Epoch %d\" % epoch)\n",
        "\n",
        "        for i in range(len(matrix)):\n",
        "            prediction = predict(matrix[i][:-1], weights)  # get predicted classificaion\n",
        "            error = matrix[i][-1]-prediction\t\t # get error from real classification\n",
        "            if verbose:\n",
        "                sys.stdout.write(\"Training on data at index %d...\\n\" % (i))\n",
        "            for j in range(len(weights)): \t\t\t\t # calculate new weight for each node\n",
        "                if verbose:\n",
        "                    sys.stdout.write(\"\\tWeight[%d]: %0.5f --> \" % (j, weights[j]))\n",
        "                weights[j] = weights[j]+(l_rate*error*matrix[i][j])\n",
        "                if verbose:\n",
        "                    sys.stdout.write(\"%0.5f\\n\" % (weights[j]))\n",
        "\n",
        "    # if len(matrix[0])==4: plot(matrix,weights) # if 2D inputs, excluding bias\n",
        "    plot(matrix, weights, title=\"Final Epoch\")\n",
        "    return weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URr-rbWCMzFv"
      },
      "source": [
        "**Keenam, kita definisikan function 'test_weights' untuk mengetes apakah data tes kita sudah sesuai dengan hasil training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGjIRU0cyYnB"
      },
      "source": [
        "def test_weights(matrix, weights, l_rate=1.00, verbose=True):\n",
        "\n",
        "    for i in range(len(matrix)):\n",
        "        prediction = predict(matrix[i][:-1], weights)  # get predicted classificaion\n",
        "        error = matrix[i][-1]-prediction\t\t # get error from real classification\n",
        "        if verbose:\n",
        "            sys.stdout.write(\"Testing on data at index %d...\\n\" % (i))\n",
        "            print(\"Predictions:\", prediction)\n",
        "            if error == 0:\n",
        "                print(\"Correct\")\n",
        "            else:\n",
        "                print(\"Wrong\")\n",
        "\n",
        "    plot(matrix, weights, title=\"Testing\")\n",
        "    # return weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKvCJHoxNMEF"
      },
      "source": [
        "**Terakhir, kita jalankan seluruh function tadi dalam main function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rCApL4_XNUVq",
        "outputId": "367c8249-38e5-4745-dcbb-9608944c882e"
      },
      "source": [
        "def main():\n",
        "\n",
        "    nb_epoch = 10\n",
        "    l_rate = 1.0\n",
        "    plot_each_epoch = False\n",
        "    stop_early = True\n",
        "\n",
        "    part_A = True\n",
        "\n",
        "    if part_A:  # 3 inputs (including single bias input), 3 weights\n",
        "\n",
        "                   # \tBias \ti1 \t\ti2 \t\ty\n",
        "        matrix = [\t[1.00, 3.50, 0.20, 0.0],\n",
        "                    [1.00, 3.00, 0.20, 0.0],\n",
        "                    [1.00, 3.20, 0.20, 0.0],\n",
        "                    [1.00, 3.10, 0.20, 0.0],\n",
        "                    [1.00, 3.60, 0.20, 0.0],\n",
        "                    [1.00, 3.90, 0.40, 0.0],\n",
        "                    [1.00, 3.40, 0.30, 0.0],\n",
        "                    [1.00, 3.40, 0.20, 0.0],\n",
        "                    [1.00, 2.90, 0.20, 0.0],\n",
        "                    [1.00, 3.10, 0.10, 0.0],\n",
        "                    [1.00, 3.70, 0.20, 0.0],\n",
        "                    [1.00, 3.40, 0.20, 0.0],\n",
        "                    [1.00, 3.00, 0.10, 0.0],\n",
        "                    [1.00, 3.00, 0.10, 0.0],\n",
        "                    [1.00, 4.00, 0.20, 0.0],\n",
        "                    [1.00, 4.40, 0.40, 0.0],\n",
        "                    [1.00, 3.90, 0.40, 0.0],\n",
        "                    [1.00, 3.50, 0.30, 0.0],\n",
        "                    [1.00, 3.80, 0.30, 0.0],\n",
        "                    [1.00, 3.80, 0.30, 0.0],\n",
        "                    [1.00, 3.40, 0.20, 0.0],\n",
        "                    [1.00, 3.70, 0.40, 0.0],\n",
        "                    [1.00, 3.60, 0.20, 0.0],\n",
        "                    [1.00, 3.30, 0.50, 0.0],\n",
        "                    [1.00, 3.40, 0.20, 0.0],\n",
        "                    [1.00, 3.00, 0.20, 0.0],\n",
        "                    [1.00, 3.40, 0.40, 0.0],\n",
        "                    [1.00, 3.50, 0.20, 0.0],\n",
        "                    [1.00, 3.40, 0.20, 0.0],\n",
        "                    [1.00, 3.20, 0.20, 0.0],\n",
        "                    [1.00, 3.10, 0.20, 0.0],\n",
        "                    [1.00, 3.40, 0.40, 0.0],\n",
        "                    [1.00, 4.10, 0.10, 0.0],\n",
        "                    [1.00, 4.20, 0.20, 0.0],\n",
        "                    [1.00, 3.10, 0.10, 0.0],\n",
        "                    [1.00, 3.20, 0.20, 0.0],\n",
        "                    [1.00, 3.50, 0.20, 0.0],\n",
        "                    [1.00, 3.10, 0.10, 0.0],\n",
        "                    [1.00, 3.00, 0.20, 0.0],\n",
        "                    [1.00, 3.40, 0.20, 0.0],\n",
        "                    [1.00, 3.50, 0.30, 0.0],\n",
        "                    [1.00, 2.30, 0.30, 0.0],\n",
        "                    [1.00, 3.20, 0.20, 0.0],\n",
        "                    [1.00, 3.50, 0.60, 0.0],\n",
        "                    [1.00, 3.80, 0.40, 0.0],\n",
        "                    [1.00, 3.30, 2.50, 1.0],\n",
        "                    [1.00, 2.70, 1.90, 1.0],\n",
        "                    [1.00, 3.00, 2.10, 1.0],\n",
        "                    [1.00, 2.90, 1.80, 1.0],\n",
        "                    [1.00, 3.00, 2.20, 1.0],\n",
        "                    [1.00, 3.00, 2.10, 1.0],\n",
        "                    [1.00, 2.50, 1.70, 1.0],\n",
        "                    [1.00, 2.90, 1.80, 1.0],\n",
        "                    [1.00, 2.50, 1.80, 1.0],\n",
        "                    [1.00, 3.60, 2.50, 1.0],\n",
        "                    [1.00, 3.20, 2.00, 1.0],\n",
        "                    [1.00, 2.70, 1.90, 1.0],\n",
        "                    [1.00, 3.00, 2.10, 1.0],\n",
        "                    [1.00, 2.50, 2.00, 1.0],\n",
        "                    [1.00, 2.80, 2.40, 1.0],\n",
        "                    [1.00, 3.20, 2.30, 1.0],\n",
        "                    [1.00, 3.00, 1.80, 1.0],\n",
        "                    [1.00, 3.80, 2.20, 1.0],\n",
        "                    [1.00, 2.60, 2.30, 1.0],\n",
        "                    [1.00, 2.20, 1.50, 1.0],\n",
        "                    [1.00, 3.20, 2.30, 1.0],\n",
        "                    [1.00, 2.80, 2.00, 1.0],\n",
        "                    [1.00, 2.80, 2.00, 1.0],\n",
        "                    [1.00, 2.70, 1.80, 1.0],\n",
        "                    [1.00, 3.30, 2.10, 1.0],\n",
        "                    [1.00, 3.20, 1.80, 1.0],\n",
        "                    [1.00, 2.80, 1.80, 1.0],\n",
        "                    [1.00, 3.00, 1.80, 1.0],\n",
        "                    [1.00, 2.80, 2.10, 1.0],\n",
        "                    [1.00, 3.00, 1.60, 1.0],\n",
        "                    [1.00, 2.80, 1.90, 1.0],\n",
        "                    [1.00, 3.80, 2.00, 1.0],\n",
        "                    [1.00, 2.80, 2.20, 1.0],\n",
        "                    [1.00, 2.80, 1.50, 1.0],\n",
        "                    [1.00, 2.60, 1.40, 1.0],\n",
        "                    [1.00, 3.00, 2.30, 1.0],\n",
        "                    [1.00, 3.40, 2.40, 1.0],\n",
        "                    [1.00, 3.10, 1.80, 1.0],\n",
        "                    [1.00, 3.00, 1.80, 1.0],\n",
        "                    [1.00, 3.10, 2.10, 1.0],\n",
        "                    [1.00, 3.10, 2.40, 1.0],\n",
        "                    [1.00, 3.10, 2.30, 1.0],\n",
        "                    [1.00, 2.70, 1.90, 1.0],\n",
        "                    [1.00, 3.20, 2.30, 1.0],\n",
        "                    [1.00, 3.30, 2.50, 1.0]]\n",
        "        weights = [\t -0.50,\t-1.50,  3.00\t ]  # initial weights specified in problem\n",
        "        # \tBias \ti1 \t\ti2 \t\ty\n",
        "        matrixTest = [\t[1.00, 3.00, 0.30, 0.0],\n",
        "                        [1.00, 3.80, 0.20, 0.0],\n",
        "                        [1.00, 3.20, 0.20, 0.0],\n",
        "                        [1.00, 3.70, 0.20, 0.0],\n",
        "                        [1.00, 3.30, 0.20, 0.0],\n",
        "                        [1.00, 3.00, 2.30, 1.0],\n",
        "                        [1.00, 2.50, 1.90, 1.0],\n",
        "                        [1.00, 3.00, 2.00, 1.0],\n",
        "                        [1.00, 3.40, 2.30, 1.0],\n",
        "                        [1.00, 3.00, 1.80, 1.0]]\n",
        "\n",
        "    else:  # 2 inputs (including single bias input), 2 weights\n",
        "\n",
        "        nb_epoch = 1000\n",
        "\n",
        "        # \tBias \ti1 \t\ty\n",
        "        matrix = [\t[1.00,\t0.08,\t1.0],\n",
        "                   [1.00,\t0.10,\t0.0],\n",
        "                   [1.00,\t0.26,\t1.0],\n",
        "                   [1.00,\t0.35,\t0.0],\n",
        "                   [1.00,\t0.45,\t1.0],\n",
        "                   [1.00,\t0.60,\t1.0],\n",
        "                   [1.00,\t0.70,\t0.0],\n",
        "                   [1.00,\t0.92,\t0.0]]\n",
        "        weights = [\t 0.20,\t1.00\t\t]  # initial weights specified in problem\n",
        "\n",
        "    train_weights(matrix, weights=weights, nb_epoch=nb_epoch, l_rate=l_rate,\n",
        "                  do_plot=plot_each_epoch, stop_early=stop_early)\n",
        "\n",
        "    test_weights(matrixTest, weights=weights)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Epoch 0 \n",
            "Weights:  [-0.5, -1.5, 3.0]\n",
            "Accuracy:  0.9555555555555556\n",
            "Training on data at index 0...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 1...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 2...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 3...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 4...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 5...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 6...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 7...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 8...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 9...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 10...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 11...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 12...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 13...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 14...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 15...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 16...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 17...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 18...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 19...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 20...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 21...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 22...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 23...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 24...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 25...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 26...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 27...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 28...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 29...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 30...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 31...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 32...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 33...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 34...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 35...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 36...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 37...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 38...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 39...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 40...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 41...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 42...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 43...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 44...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 45...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 46...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 47...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 48...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 49...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 50...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 51...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 52...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 53...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 54...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 55...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 56...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 57...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 58...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 59...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 60...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 61...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 62...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 63...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 64...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 65...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 66...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 67...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 68...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 69...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 70...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 71...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 72...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 73...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -1.50000 --> -1.50000\n",
            "\tWeight[2]: 3.00000 --> 3.00000\n",
            "Training on data at index 74...\n",
            "\tWeight[0]: -0.50000 --> 0.50000\n",
            "\tWeight[1]: -1.50000 --> 1.50000\n",
            "\tWeight[2]: 3.00000 --> 4.60000\n",
            "Training on data at index 75...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 76...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 77...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 78...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 79...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 80...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 81...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 82...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 83...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 84...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 85...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 86...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 87...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 88...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Training on data at index 89...\n",
            "\tWeight[0]: 0.50000 --> 0.50000\n",
            "\tWeight[1]: 1.50000 --> 1.50000\n",
            "\tWeight[2]: 4.60000 --> 4.60000\n",
            "Predictions: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Epoch 1 \n",
            "Weights:  [0.5, 1.5, 4.6]\n",
            "Accuracy:  0.5\n",
            "Training on data at index 0...\n",
            "\tWeight[0]: 0.50000 --> -0.50000\n",
            "\tWeight[1]: 1.50000 --> -2.00000\n",
            "\tWeight[2]: 4.60000 --> 4.40000\n",
            "Training on data at index 1...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 2...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 3...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 4...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 5...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 6...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 7...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 8...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 9...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 10...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 11...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 12...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 13...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 14...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 15...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 16...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 17...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 18...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 19...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 20...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 21...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 22...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 23...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 24...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 25...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 26...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 27...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 28...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 29...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 30...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 31...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 32...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 33...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 34...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 35...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 36...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 37...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 38...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 39...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 40...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 41...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 42...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 43...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 44...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 45...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 46...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 47...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 48...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 49...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 50...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 51...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 52...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 53...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 54...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 55...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 56...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 57...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 58...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 59...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 60...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 61...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 62...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 63...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 64...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 65...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 66...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 67...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 68...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 69...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 70...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 71...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 72...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 73...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 74...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 75...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 76...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 77...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 78...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 79...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 80...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 81...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 82...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 83...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 84...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 85...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 86...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 87...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 88...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Training on data at index 89...\n",
            "\tWeight[0]: -0.50000 --> -0.50000\n",
            "\tWeight[1]: -2.00000 --> -2.00000\n",
            "\tWeight[2]: 4.40000 --> 4.40000\n",
            "Predictions: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Epoch 2 \n",
            "Weights:  [-0.5, -2.0, 4.3999999999999995]\n",
            "Accuracy:  1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Testing on data at index 0...\n",
            "Predictions: 0.0\n",
            "Correct\n",
            "Testing on data at index 1...\n",
            "Predictions: 0.0\n",
            "Correct\n",
            "Testing on data at index 2...\n",
            "Predictions: 0.0\n",
            "Correct\n",
            "Testing on data at index 3...\n",
            "Predictions: 0.0\n",
            "Correct\n",
            "Testing on data at index 4...\n",
            "Predictions: 0.0\n",
            "Correct\n",
            "Testing on data at index 5...\n",
            "Predictions: 1.0\n",
            "Correct\n",
            "Testing on data at index 6...\n",
            "Predictions: 1.0\n",
            "Correct\n",
            "Testing on data at index 7...\n",
            "Predictions: 1.0\n",
            "Correct\n",
            "Testing on data at index 8...\n",
            "Predictions: 1.0\n",
            "Correct\n",
            "Testing on data at index 9...\n",
            "Predictions: 1.0\n",
            "Correct\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}